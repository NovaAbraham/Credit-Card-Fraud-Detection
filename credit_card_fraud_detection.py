# -*- coding: utf-8 -*-
"""Credit Card Fraud Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1e56yx8youdd1p1LAdfR-IAqw8R2BC8c5
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder

train=pd.read_csv('fraudTrain.csv')
test=pd.read_csv('fraudTest.csv')

train.head(2)

test.head(2)

train.info()

train.describe()

train.shape

train.isnull().sum()

sns.heatmap(train.isnull())

def cleaning_data(clean):
    clean.drop(["Unnamed: 0",'cc_num','first', 'last', 'street', 'city', 'state', 'zip', 'dob', 'trans_num','trans_date_trans_time'],axis=1, inplace=True)
    clean.dropna()
    return clean

cleaning_data(train)

cleaning_data(test)

train.head(1)

train['gender'] = train['gender'].map({'M': 0, 'F': 1})

train.info()

encoder = LabelEncoder()
def encode(data):
    data["merchant"] = encoder.fit_transform(data["merchant"])
    data["category"] = encoder.fit_transform(data["category"])
    data["gender"] = encoder.fit_transform(data["gender"])
    data["job"] = encoder.fit_transform(data["job"])
    return data

encode(train)

encode(test)

exit_counts = train["is_fraud"].value_counts()
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)  # Subplot for the pie chart
plt.pie(exit_counts, labels=["No", "YES"], autopct="%0.0f%%")
plt.title("is_fraud Counts")
plt.tight_layout()  # Adjust layout to prevent overlapping
plt.show()

train.corr()

sns.heatmap(train.corr(),annot=True,cmap='coolwarm', fmt=".2f")

x = train.drop(columns=["is_fraud"], inplace = False)
y = train["is_fraud"]

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

model1 = LogisticRegression()
model2 = RandomForestClassifier()
model3 = DecisionTreeClassifier()

columns = ['LogisticRegression', 'RandomForestClassifier' , 'DecisionTreeClassifier']
accuracies=[]

def cal (model):
    model.fit(x_train, y_train)
    predictions = model.predict(x_test)
    accuracy = accuracy_score(y_test, predictions)

    accuracies.append(accuracy)

    print("-----Model Evaluation on Test Data-----")
    print(model)
    print()
    print(accuracy)

#LogisticRegression
cal(model1)

#RandomForestClassifier
cal(model2)

#DecisionTreeClassifier
cal(model3)

accuracies

FinalResult=pd.DataFrame({'Algorithm':columns, 'Accuracy':accuracies})

FinalResult

fig,ax=plt.subplots(figsize=(20,5))
plt.plot(FinalResult.Algorithm,accuracies,label="Accuracy")
plt.legend()
plt.show()

x_test = test.drop(columns=["is_fraud"], inplace = False)
y_test = test["is_fraud"]

#RandomForestClassifier
y_pred = model2.predict(x_test)
y_pred

accuracy = accuracy_score(test['is_fraud'],y_pred)
accuracy